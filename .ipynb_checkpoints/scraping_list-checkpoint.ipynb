{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# from urllib2 import urlopen\n",
    "import re\n",
    "import requests\n",
    "import webbrowser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 林草"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"http://www.forestry.gov.cn\"\n",
    "url_index = \"/sites/main/main/gov/govindex.jsp\"\n",
    "\n",
    "param = {\n",
    "    'p': '1', \n",
    "    'textfield2': '林业生态', \n",
    "    'startdt': '2002-01-01', \n",
    "    'stopdt': '2099-12-30', \n",
    "    'govtypeid': '0', \n",
    "    'typeid': '0', \n",
    "    'page': 1\n",
    "}\n",
    "\n",
    "all_title = []\n",
    "all_href = []\n",
    "all_date = []\n",
    "all_number = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, 6):\n",
    "    param['page'] = page\n",
    "    r = requests.get(url_base+url_index, params=param)\n",
    "    soup = BeautifulSoup(r.text, features='lxml')\n",
    "    \n",
    "    all_document_a = soup.find_all('a', {'class': 'tooltip'})\n",
    "    all_title.extend([d.get_text() for d in all_document_a])\n",
    "    all_href.extend([d['href'] for d in all_document_a])\n",
    "\n",
    "    all_date_td = soup.find_all('td', {'class':'border_bottom_c2ceb3', 'width':'100'})\n",
    "    all_date.extend([d.get_text() for d in all_date_td])\n",
    "\n",
    "    all_number_td = soup.find_all('td', {'class':'border_bottom_c2ceb3', 'width':'130'})\n",
    "    all_number.extend([d.get_text() for d in all_number_td])\n",
    "    \n",
    "all_href = [url_base+h for h in all_href]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    u'公文名称': all_title, \n",
    "    u'发文日期': all_date, \n",
    "    u'文号': all_number, \n",
    "    u'正文链接': all_href\n",
    "})\n",
    "\n",
    "column = [u'公文名称', u'发文日期', u'文号', u'正文链接']\n",
    "\n",
    "df.to_csv(u'林草信息公开.csv', index=False, encoding='utf_8_sig', columns=column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 政府"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_search = \"http://sousuo.gov.cn/list.htm\"\n",
    "\n",
    "param = {\n",
    "    'q': '林业生态',\n",
    "    'n': 15, \n",
    "    'p': 0, \n",
    "    't': 'paper', \n",
    "    'sort': 'publishDate', \n",
    "    # childtype: \n",
    "    # subchildtype: \n",
    "    # pcodeJiguan: \n",
    "    # pcodeYear: \n",
    "    # pcodeNum: \n",
    "    # location: \n",
    "    'searchfield': 'title:content:pcode:puborg:keyword', \n",
    "    # title: \n",
    "    # content: \n",
    "    # pcode: \n",
    "    # puborg: \n",
    "    'timetype': 'timeqb'\n",
    "    # mintime: \n",
    "    # maxtime: \n",
    "}\n",
    "\n",
    "all_title = []\n",
    "all_href = []\n",
    "all_index = []\n",
    "all_class = []\n",
    "all_dept = []\n",
    "all_date_f = []\n",
    "all_number = []\n",
    "all_date_p = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(16):\n",
    "    param['p'] = p\n",
    "    r = requests.get(url_search, params=param)\n",
    "#     webbrowser.open(r.url)\n",
    "    soup = BeautifulSoup(r.content, features='lxml')\n",
    "    all_document = soup.find_all('td', {'class': 'info'})\n",
    "    \n",
    "    for d in all_document:\n",
    "#         all_title.append(d.a.text)\n",
    "        all_href.append(d.a['href'])\n",
    "        all_info = [re.findall(r\"</strong>(.*?)</li>\", unicode(i))[0] \n",
    "                    for i in BeautifulSoup(unicode(d), features=\"lxml\").find_all('li')]\n",
    "#         print type(all_info)\n",
    "        all_index.append(all_info[0])\n",
    "        all_class.append(all_info[1])\n",
    "        all_dept.append(all_info[2])\n",
    "        all_date_f.append(all_info[3])\n",
    "        all_title.append(all_info[4])\n",
    "        all_number.append(all_info[5])\n",
    "        all_date_p.append(all_info[6])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    u'公文名称': all_title, \n",
    "    u'正文链接': all_href, \n",
    "    u'主题分类': all_class, \n",
    "    u'发文机关': all_dept, \n",
    "    u'索引号': all_index, \n",
    "    u'发文字号': all_number, \n",
    "    u'成文日期': all_date_f, \n",
    "    u'发布日期': all_date_p\n",
    "})\n",
    "\n",
    "column = [\n",
    "    u'公文名称', \n",
    "    u'正文链接', \n",
    "    u'主题分类', \n",
    "    u'发文机关', \n",
    "    u'索引号', \n",
    "    u'发文字号', \n",
    "    u'成文日期', \n",
    "    u'发布日期'\n",
    "]\n",
    "\n",
    "df.to_csv(u'政府信息公开.csv', index=False, encoding='utf_8_sig', columns=column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 发改委"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_search = \"https://so.ndrc.gov.cn/api/query\"\n",
    "\n",
    "param = {\n",
    "    'qt': '林业生态',\n",
    "    'tab': 'all', \n",
    "    'page': 1, \n",
    "    'pageSize': 20,\n",
    "    'siteCode': 'bm04000fgk', \n",
    "    'key': 'CAB549A94CF659904A7D6B0E8FC8A7E9', \n",
    "#     startDateStr: \n",
    "#     endDateStr: \n",
    "    'timeOption': 0, \n",
    "    'sort': 'dateDesc'\n",
    "}\n",
    "\n",
    "page = 1\n",
    "all_title = []\n",
    "all_href = []\n",
    "all_date = []\n",
    "\n",
    "while page:\n",
    "    param['page'] = page\n",
    "    r = requests.get(url_search, params=param)\n",
    "    if r.status_code == 200:\n",
    "        r_json = json.loads(r.content)\n",
    "        all_title.extend(jsonpath.jsonpath(r_json,\"$..title\"))\n",
    "        all_href.extend(jsonpath.jsonpath(r_json,\"$..url\"))\n",
    "        all_date.extend(jsonpath.jsonpath(r_json,\"$..publishTime\"))\n",
    "    else:\n",
    "        page = -1\n",
    "\n",
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
